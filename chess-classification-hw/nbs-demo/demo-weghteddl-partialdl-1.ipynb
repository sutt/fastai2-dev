{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use DataLoader Helpers\n",
    " Classes: `WeightedDL`, `PartialDL`\n",
    " \n",
    "Building Dummy examples from the [docs](https://dev.fast.ai/callback.data) where data items are just numbers \n",
    "\n",
    "Building Tiny-MNIST examples where the data is images + labels, and a train/valid split is inevitable. For these reasons, several variations to the dummy recipe need to be accounted for.\n",
    "\n",
    "I think I duplicated a lot of work from here: [https://dev.fast.ai/data.transforms#End-to-end-dataset-example-with-MNIST](https://dev.fast.ai/data.transforms#End-to-end-dataset-example-with-MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiny-MNIST: Explore DataPath Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/user/.fastai/data/mnist_tiny/labels.csv'),\n",
       " Path('/home/user/.fastai/data/mnist_tiny/models'),\n",
       " Path('/home/user/.fastai/data/mnist_tiny/test'),\n",
       " Path('/home/user/.fastai/data/mnist_tiny/train'),\n",
       " Path('/home/user/.fastai/data/mnist_tiny/valid')]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in path.ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/home/user/.fastai/data/mnist_tiny/train/3'),\n",
       " Path('/home/user/.fastai/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[e for e in (path/'train').ls()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What I usually do\n",
    "Create a DataLoader right from the beginning.\n",
    "\n",
    "Instead, we'll need to create a `Datasets` and go from that into a `WeightedDL` or a `ParitalDL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ImageDataLoaders.from_folder(path,\n",
    "                                  seed=0,\n",
    "                                  valid_pct=0.2,\n",
    "                                  num_workers=0,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Dummy `WeightedDL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=8\n",
    "made_dsets = Datasets(torch.arange(n).float())\n",
    "\n",
    "made_wdl = made_dsets.weighted_dataloaders(wgts=range(n), bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([5., 6., 6., 7., 4., 4., 6., 6.]),)\n",
      "(tensor([4., 6., 4., 6., 4., 6., 7., 7.]),)\n",
      "(tensor([7., 5., 5., 5., 1., 3., 2., 6.]),)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(3): print(made_wdl.one_batch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to build a Tiny-MNIST `WeightedDL`\n",
    "Major differences:\n",
    " - here we go to a Dataset from a DataBlock\n",
    " - dataset directory specfic logic: need to handle loading item/label\n",
    "   - this can also be gotten around by specifying in datablock `splitter=GrandParentSplitter()`\n",
    " - dsets will be split with poritions of data in train vs split\n",
    "   - therefore, we need to insert wgts of length equal to dsets.train.items\n",
    " - need to add on `after_item=Pipeline([ToTensor()])` to build the DataLoader so that it can run batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_get_image_files(p):\n",
    "    ''' removes /test/ directory files from returned items'''\n",
    "    \n",
    "    return [it for it in  get_image_files(p) \n",
    "            if parent_label(it) != 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(blocks = (ImageBlock(cls=PILImageBW),CategoryBlock),\n",
    "                  get_items = my_get_image_files,\n",
    "                  splitter = GrandparentSplitter(),\n",
    "                  get_y = parent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting items from /home/user/.fastai/data/mnist_tiny\n",
      "Found 1408 items\n",
      "2 datasets of sizes 709,699\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize\n"
     ]
    }
   ],
   "source": [
    "dsets = mnist.datasets(untar_data(URLs.MNIST_TINY), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) ['3','7']"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1408, 709)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets), len(dsets.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1] [6, 6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "p3, p7 = 1, 6\n",
    "\n",
    "wgts = [p3 if parent_label(e) == '3' else p7 \n",
    "        for e in dsets.train.items]\n",
    "\n",
    "print(wgts[:5], wgts[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_wdl = dsets.weighted_dataloaders(\n",
    "                                #wgts=range(len(dsets.train)), \n",
    "                                wgts=wgts,\n",
    "                                bs=16,\n",
    "                                after_item=Pipeline([ToTensor()]),\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.data.core.DataLoaders at 0x7f37cca9cb50>"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorCategory([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_wdl.one_batch()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorCategory([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mnist_wdl[0].shuffle, mnist_wdl[1].shuffle)\n",
    "mnist_wdl[1].one_batch()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the batch heavily over-emphasize the 1-class (sevens) over the 0-class (threes) in training set (which is shuffled) while the validation is not shuffled and remains in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Dummy `PartialDL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=160\n",
    "made_dsets = Datasets(torch.arange(n).float())\n",
    "\n",
    "made_pdl = made_dsets.partial_dataloaders(partial_n=30, bs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 15.,  74.,  51., 158., 157., 153., 118.,  54.]),)\n",
      "(tensor([150.,  37., 135.,  34.,  17., 102., 140.,  47.]),)\n",
      "(tensor([ 67., 145., 125.,  91.,  72.,   8.,  28.,  11.]),)\n"
     ]
    }
   ],
   "source": [
    "for b in made_pdl[0]:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tiny-MNIST `PartialDL`\n",
    "Again, add `after_item` method to turn PILs (created from Paths) into Tensors which are valid type to do a batch with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pdl = dsets.partial_dataloaders(\n",
    "                    partial_n=64, \n",
    "                    bs=12,\n",
    "                    after_item=Pipeline([ToTensor()]),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for e in my_pdl[0]:\n",
    "    print(len(e[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f37cbd1e9d0>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAD4klEQVR4nO3aX2jVZRzH8dfZnHNqzkil1IhM+7PdlP3VklZmgZEgUfZH7C/lhWEziiAjBKNdeKHUIqFCCq3IReWFRRdlkGaGNmOlYhqWNf+EZZa27Zx18dvKPZ4dN3fONup53/w45/nyez58zmfP7/k+v6VaW1tF/qWorwX0N6IhAdGQgGhIQDQkYECuwWlFt/1nH0EfZd5OZfs+JiQgGhIQDQmIhgREQwKiIQHRkICc+5CeUjR4MDh6bSUoXbupw3hj9WRQ/fBq9w7bD9KtGXDn7mngq0/PB+OXfZeM79tfSMkxISGpXOchPd2pFo84A7y0+T3QmC7tMF5RkgalqZKT3quhqQXMXl4NxtSs74m0uFPtKgVdQzQ1g/t23AXWXLgalKSK2wq6/ntUDkyk3jP7Q/DJm8m61PL9nnwo/YeYkICCJiR9+HAyyQ3J9eKa+WD93UtAedGgbt/z0dN3gLprkqdQeUxIYSnsGhJw7pMbwC1bHwPNZScu9Jm2B87Gp1/oNV3HExMS0KsJaWfYqs9P/LIoefI0zr+yl9UEMvp09n5InyQkGz8tSJKxufr5nHV1R0aA4Q2/g3wf+saEBPSLhPywcLIv5y5t+1Sctea1w2PA6llVoHVrQ0G0xIQE9EpCMlMuAbseSj7XTlrVYXxi6WdKUrl3rTVrZoJxWzfkX+BxxIQEFLaXqZoIFr6yAlw9qLmTys7TMe3BuWD8unqQyZu67BTEkJapl4IFy1cilxEnZ8/NSYgvWNdzXV0h/skEFCQhxx4/BG4s+yNn3aHMMbCteYhJpemsNdtnvggq/pwHxj0RF9VepSAJSb8+Cjww7zqwZOzaDuOL91WBDbWXgeE7j3ljVdLud3Zo9NSMOvDWyqkgU/9tfkW3ERMSUNDXEN2heORIcNEHv4CaMzdlrWtv7lbcMR20bjm1LXx8DdFF+kVzB+kDB8A79cm60llCbh16ECytPA2Ub8mvjpiQgH6TkHYqFicJcFPfzB8TEpCXhAwYMxp8s3AsqHh2L2j5cW+377Xz/rPyIemUiQkJyEtCDl5/DtgxI9ltPnNVciD0ceMEMGzRkKRw49fJNcvep3jCODCw8recc/2cPprUHSnMQUBMSEBeElLclPziRzJ/gUWjtnS4StoQE5c9As5+dTtIDUimb5ow2pyX3we3D83+L1PtnfGcbbNB2btf5EP6CcSEBOS1l9n93CTQMCf3i+raX88Dl5ftAleUnnyaKfWzQPn0nd2R1Cmxl+ki/abb7W1iQrpINCQgGhIQDQmIhgREQwKiIQE59yH/R2JCAqIhAdGQgGhIQDQkIBoS8DdZbfXQqI9BVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(my_pdl.one_batch()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
