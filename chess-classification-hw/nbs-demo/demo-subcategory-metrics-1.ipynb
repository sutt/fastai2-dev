{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subcategory Metrics: `piece-class` vs `piece-color`\n",
    "Build functions to turn any learner or evaluation routine, and eventually any train-loop (via `fastai2.metrics`) into reporting where the difference mis-classification is occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from modules.trainutils import build_dl, piece_class_parse\n",
    "from modules.trainutils import my_metrics, stratify_sample\n",
    "from modules.trainutils import show_cf, piece_class_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path('../../../other-chess-data/regulation-test-2-easy/')\n",
    "train_path = Path('../../../rf-chess-data/cropped_v1/')\n",
    "\n",
    "n = 200\n",
    "seed=42\n",
    "\n",
    "test_dl = build_dl(test_path, n=None)\n",
    "\n",
    "train_dl = ImageDataLoaders.from_name_func(\n",
    "                train_path, \n",
    "                # get_image_files(train_path),\n",
    "                stratify_sample(train_path, n=n, np_seed=seed),\n",
    "                valid_pct=0.2, \n",
    "                seed=42,\n",
    "                label_func=piece_class_parse, \n",
    "                item_tfms=RandomResizedCrop(128, min_scale=0.5),\n",
    "                batch_tfms=aug_transforms(),\n",
    "                # num_workers=1, # turn on for debugging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = load_learner('../models/expmod-b-1.pkl')\n",
    "learn = load_learner('../models/stadard-piece-2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_test_dl = learn.dls.test_dl(get_image_files(test_path), \n",
    "                                 with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn.get_preds(dl=test_dl.train, with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.data.core.TfmdDL at 0x7f59d00dbc10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds2 = learn.get_preds(dl=good_test_dl, with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 162)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds[0]), len(preds2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = preds\n",
    "\n",
    "y_actual = p[1].tolist()\n",
    "y_hat =    torch.argmax(p[0], dim=1).tolist()\n",
    "y_loss =   p[2].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'black-bishop',\n",
       " 1: 'black-king',\n",
       " 2: 'black-knight',\n",
       " 3: 'black-pawn',\n",
       " 4: 'black-queen',\n",
       " 5: 'black-rook',\n",
       " 6: 'white-bishop',\n",
       " 7: 'white-king',\n",
       " 8: 'white-knight',\n",
       " 9: 'white-pawn',\n",
       " 10: 'white-queen',\n",
       " 11: 'white-rook'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_fullclass = {i:v for i,v in enumerate(list(test_dl.vocab))}\n",
    "d_fullclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_colorclass = {'black':0, 'white':1}\n",
    "d_piececlass = {'bishop':1, 'king':1, 'knight':2, 'pawn':3, 'queen':4,\n",
    "                'rook':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subcat_parse(class_label, color=False, piece=False):\n",
    "    color_label, piece_label = class_label.split('-')\n",
    "    color_ind = d_colorclass[color_label]\n",
    "    piece_ind = d_piececlass[piece_label]\n",
    "    if color: return color_ind\n",
    "    if piece: return piece_ind\n",
    "    return color_ind, piece_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual_color = [subcat_parse(d_fullclass[e], color=True) for e in y_actual]\n",
    "y_actual_piece = [subcat_parse(d_fullclass[e], piece=True) for e in y_actual]\n",
    "\n",
    "y_hat_color = [subcat_parse(d_fullclass[e], color=True) for e in y_hat]\n",
    "y_hat_piece = [subcat_parse(d_fullclass[e], piece=True) for e in y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare model perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece</th>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "overall  0.117\n",
       "color    0.537\n",
       "piece    0.241"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_actual, y_hat)\n",
    "acc_color = accuracy_score(y_actual_color, y_hat_color)\n",
    "acc_piece = accuracy_score(y_actual_piece, y_hat_piece)\n",
    "\n",
    "pd.DataFrame([acc, acc_color, acc_piece], \n",
    "             index=['overall', 'color', 'piece']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verify the transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai2]",
   "language": "python",
   "name": "conda-env-fastai2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
